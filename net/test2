from sklearn import datasets
from sklearn.utils.extmath import softmax
import numpy as np
from matplotlib import pyplot
from sklearn.preprocessing import OneHotEncoder
from activation import *
import random

class Network:
    def __init__(self):
        self.layers = []
        self.input = None

        self.output = None

        self.x = None
        self.y = None

        self.y_hot = None
        self.classes = None

        self.delta_ouput = None

        self.lrate = 0.01

    def forward(self):
        input = self.input

        for i,l in enumerate(self.layers):
            #print ("Layer " , i)
            input = l.forward_prop(input)
            #print (input.shape , input)
        net.output = self.layers[-1].h_output

    def backward(self):

        error = (net.y_hot - net.output)
        delta = error * sigmoid(self.layers[-1].h_output, deriv=True)
        delta = error
        delta = np.array([np.sum(error,axis=0)/len(self.input)])
        for i in range(len(self.layers)-1,-1,-1):
            #print (i)
            self.layers[i].backward_prop(delta)
            delta = self.layers[i].back_x

    def update(self):

        # sum delta

        for i in range(0,len(self.layers)):
            layer = self.layers[i]

            layer.dWeight =  self.lrate * layer.delta
            layer.weights += layer.dWeight #* layer.output

    def calculate_loss(self,type):
        net.y_hot = self.one_hot(self.classes,y)

        if type == "sse":
            loss = ((net.output - net.y_hot) ** 2)/2
            avg_loss = np.sum(loss)/len(y)

        self.delta_ouput = loss
        return loss,avg_loss

    def one_hot(self, n, x):
        encod = []
        for i in x:
            temp = [0] * n
            temp[i] = 1
            encod.append(temp)
        return np.array(encod)

class Layer:
    def __init__(self, input_shape, output_shape, activation ):
        self.weights =  np.random.rand(input_shape,output_shape)
        self.bias = np.random.rand(output_shape)

        self.dWeight = np.random.rand(output_shape,input_shape)
        self.dBias = None

        self.activation = activation
        self.shape = output_shape

        self.delta = None

        self.output = None
        self.h_output = None

    def forward_prop(self, x ):

        self.output = np.dot(x, self.weights) /(self.shape)

        if self.activation == "relu":
            self.h_output = relu(self.output)

        elif self.activation == "sigmoid":
            self.h_output = sigmoid(self.output)

        elif self.activation == "tanh":
            self.h_output = tanh(self.output)

        return self.h_output

    def backward_prop(self,delta_plus):

        self.back_x = np.dot(delta_plus, self.weights.T)

        if self.activation == "sigmoid":
            self.delta = delta_plus * sigmoid(self.output, deriv=True)

        elif self.activation == "tanh":
            self.delta = delta_plus * tanh(self.output, deriv=True)

        elif self.activation == "relu":
            self.delta = delta_plus * relu(self.output, deriv=True)
        return self.back_x

    def update_weight(self):
        pass

data = datasets.load_digits()

batch_size= 1
x = data.data[:batch_size]
x = x/15
y = data.target[:batch_size]

input = x.T

layer1 = Layer(x.shape[1],20,"sigmoid")
layer2 = Layer(layer1.shape,16,"sigmoid")
layer3 = Layer(layer2.shape,18,"sigmoid")
layer4 = Layer(layer3.shape,10,"sigmoid")


net = Network()
net.classes = 10
net.layers += [layer1,layer2,layer3,layer4]
net.input = x
net.y = y

# forward prop
correct = 0
for i in range(100000):

    n = random.randint(1+batch_size,1797-batch_size)
    #n= 4
    x = data.data[n-1:n+batch_size-1]/15
    y = data.target[n-1:n+batch_size-1]

    net.input = x
    net.y = y

    net.forward()
    loss =  net.calculate_loss("sse")
    #print (i,loss[1],loss[0],net.output)
    net.backward()
    net.update()

    if y[0] == np.argmax(sigmoid(layer4.output)):
        correct+=1
    #print (layer4.output,loss[1])
    if (i%1000 == 0):

        print (y,np.argmax(sigmoid(layer4.output)),correct)
        correct = 0
print("My Net")

# predict
import PyQt5
